{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from os.path import join\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept2cat = {row.concept.lower() : row.category.lower() for i, row in  pd.read_excel(\"../data/best_human_exemplars.xlsx\").iterrows()}\n",
    "cat_en2it = {\n",
    "    'animals': 'animali',\n",
    "    'body parts': 'parti del corpo',\n",
    "    'clothes': 'vestiti',\n",
    "    'foods': 'cibi',\n",
    "    'furnishings/fittings': 'arredamenti/accessori',\n",
    "    'furniture': 'mobili',\n",
    "    'hobbies': 'passatempi',\n",
    "    'housing buildings': 'edifici residenziali',\n",
    "    'kitchenware': 'utensili da cucina',\n",
    "    'plants': 'piante',\n",
    "    'stationery': 'cancelleria',\n",
    "    'vehicles': 'veicoli'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_generations(base_dir, model, modality, language):\n",
    "    temp = base_dir.split(\"/\")[-1].split(\"_\")[-1]\n",
    "    if \"temp_00\" in base_dir:\n",
    "        fname = f\"{model}-{language}-{modality}-t00_iter1.json\"\n",
    "        data = [json.load(open(join(base_dir, fname)))]\n",
    "    else:\n",
    "        fnames = [f\"{model}-{language}-{modality}-t{temp}_iter{i}.json\" for i in range(1, 6)]\n",
    "        data = [json.load(open(join(base_dir, fname))) for fname in fnames]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(generations, model_name):\n",
    "    dfs = []\n",
    "    for i, generation in enumerate(generations):\n",
    "        if \"_exp_config\" in generation: generation.pop(\"_exp_config\") \n",
    "        df = pd.DataFrame([\n",
    "            {\"participant\": f\"{model_name}-iter{i+1}\", \"category\": concept2cat[concept], \"category_it\": cat_en2it[concept2cat[concept]], \"concept\": concept, \"exemplar\": clean_exemplar(exemplar), \"clean_exemplar\": remove_concept(exemplar, concept), \"rank\": generation_rank}\n",
    "                for concept, outer_dict in generation.items()\n",
    "                for generation_rank, exemplar in outer_dict.items()\n",
    "            ])\n",
    "        dfs.append(df)\n",
    "    concat_df = pd.concat(dfs, ignore_index=True)\n",
    "    concat_df = concat_df.sort_values(by=[\"concept\", \"participant\"], ascending=[True, True])\n",
    "    return concat_df\n",
    "\n",
    "def clean_exemplar(exemplar):\n",
    "    exemplar = exemplar.rstrip(\".\")\n",
    "    return exemplar\n",
    "\n",
    "def remove_concept(exemplar, concept):\n",
    "    exemplar = clean_exemplar(exemplar)\n",
    "    plural_concept = pluralize(concept)\n",
    "    if concept in exemplar:\n",
    "        exemplar = exemplar.replace(concept, \"\", 1)\n",
    "    elif plural_concept in exemplar:\n",
    "        exemplar = exemplar.replace(plural_concept, \"\", 1)\n",
    "    exemplar = exemplar.lstrip()\n",
    "    return exemplar\n",
    "\n",
    "def pluralize(word):\n",
    "    if word.endswith('o'):\n",
    "        return word[:-1] + \"i\"\n",
    "    elif word.endswith(\"a\"):\n",
    "        return word[:-1] + \"e\"\n",
    "    elif word.endswith(\"e\"):\n",
    "        return word[:-1] + \"i\"\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_exemplars(dataframe):\n",
    "    slices = []\n",
    "    for concept in dataframe.concept.unique():\n",
    "        for participant in dataframe.participant.unique():\n",
    "            slice = dataframe[(dataframe.concept == concept) & (dataframe.participant == participant)]\n",
    "            slice = slice[slice.clean_exemplar != \"\"]\n",
    "            slice[\"rank\"] = [i + 1 for i in range(len(slice))]\n",
    "            slices.append(slice)\n",
    "    \n",
    "    df = pd.concat(slices, ignore_index=True)\n",
    "    df[\"rank\"] = df[\"rank\"].astype(\"int\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = \"temp_05\"\n",
    "base_dir = f\"italian/{temp}\"\n",
    "out_dir = f\"italian/formatted/{temp}\"\n",
    "\n",
    "model = \"llava\"\n",
    "modality = \"visual\"\n",
    "language = \"it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10719, 7) (10669, 7)\n",
      "- storing results in: italian/formatted/temp_05/llava-it-visual-temp_05_alliters.csv\n"
     ]
    }
   ],
   "source": [
    "generations = load_generations(base_dir, model, modality, language)\n",
    "gen_df = create_dataframe(generations, model_name=model)\n",
    "clean_df = remove_invalid_exemplars(gen_df)\n",
    "\n",
    "print(gen_df.shape, clean_df.shape)\n",
    "\n",
    "out_fname = f\"{model}-{language}-{modality}-{temp}_alliters.csv\"\n",
    "\n",
    "print(f\"- storing results in: {out_dir}/{out_fname}\")\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "clean_df.to_csv(join(out_dir, out_fname), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge ALL freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_freqs_p = \"freqs/all/all-freqs-sketchengine.csv\"\n",
    "andrea_freqs = \"freqs/all/all-freqs-sketchengine-andrea.csv\"\n",
    "giulia_freqs = \"freqs/all/all-freqs-sketchengine-giulia.csv\"\n",
    "cate_freqs = \"freqs/all/all-freqs-sketchengine-caterina.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv(all_freqs_p)\n",
    "\n",
    "# save a backup copy of original freqs\n",
    "all_df.to_csv(f\"{all_freqs_p}.bak\", index=False)\n",
    "\n",
    "andrea_df = pd.read_csv(andrea_freqs)\n",
    "giulia_df = pd.read_csv(giulia_freqs)\n",
    "cate_df = pd.read_csv(cate_freqs)\n",
    "\n",
    "\n",
    "new_df = pd.concat([all_df, andrea_df, giulia_df, cate_df])\n",
    "new_df = new_df.drop_duplicates(subset=\"exemplar\")  # drop duplicated exemplars\n",
    "\n",
    "new_df.to_csv(all_freqs_p, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latestorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
