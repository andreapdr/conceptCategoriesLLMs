# compute intersection between exemplars produced by human subjects and exemplars generated by LLMs (top 5 exemplars)

import os
import pandas as pd

from utils import load_datadict

def main(args):
    data_dict = load_datadict(args.temp)

    concepts = data_dict["human"].concept.str.lower().unique()
    concept2cat = {row.concept.lower(): row.category.lower() for i, row in data_dict["human"][["concept", "category"]].drop_duplicates().iterrows()}
    models = [m for m in list(data_dict.keys()) if m != "human"]

    occurrence_df = pd.DataFrame(columns=["category", "concept", "human"] + models)

    for concept in concepts:
        row_results = {}
        exemplars_human = get_topn_exemplars(data_dict["human"], concept, args.sort, n=5, filter=False) # TODO filter=args.filter)
        for model in models:
            exemplars = get_topn_exemplars(data_dict[model], concept, args.sort, n=len(exemplars_human), filter=args.filter)
            row_results[model] = exemplars
        
        row_results["concept"] = [concept for i in range(len(exemplars_human))]
        row_results["category"] = [concept2cat[concept] for i in range(len(exemplars_human))]
        row_results["human"] = exemplars_human

        unpacked_row = [{k: v[i] for k, v in row_results.items()} for i in range(len(row_results["human"]))]

        for row in unpacked_row:
            occurrence_df.loc[len(occurrence_df)] = row

    os.makedirs("results-occurrences", exist_ok=True)
    occurrence_df_outname = f"df_occ_t{str(args.temp).replace('.', '')}.csv"
    if args.filter:
        occurrence_df_outname = occurrence_df_outname.replace(".csv", ".filter.csv")
    occurrence_df.to_csv(f"results-occurrences/{occurrence_df_outname}", index=False)

    matches = pd.concat([compute_result_concept(occurrence_df, concept, models) for concept in concepts])
    sorted_columns = ["category", "concept", "human"]
    
    sorted_columns = sorted_columns + sorted(list(set([elem for elem in (models + matches.columns.to_list()) if elem not in sorted_columns])))

    matches = matches[sorted_columns]

    matches_df_outname = f"results_occ_t{str(args.temp).replace('.', '')}.csv"
    if args.filter:
        matches_df_outname = matches_df_outname.replace(".csv", ".filter.csv")
    matches.to_csv(f"results-occurrences/{matches_df_outname}", index=False)


def compute_result_concept(data, concept, models):
    target = data[data.concept == concept.upper()]
    selected = data[data.concept == concept]
    target = selected.human
    candidates = selected[models]
    match_exact, match_substring, match_substring_noconcept = compute_order_match(target, candidates, concept)
    match_intersection = compute_intersection(target, candidates, concept)

    merge_match = (match_exact | match_substring) | match_substring_noconcept
    merge_intersection = match_intersection

    merge_match = merge_match.rename(columns={name: name + "_order" for name in merge_match.columns})
    merge_intersection = merge_intersection.rename(columns={name: name + "_match" for name in merge_intersection.columns})
    
    match_df = pd.concat([selected, merge_match, merge_intersection], axis=1)

    return match_df

def compute_intersection(target, exemplar, concept):
    # TODO check for substrings?
    exemplar = exemplar.fillna("")

    simple_match = exemplar.apply(lambda row: row.apply(lambda x: True if x in target.values else False), axis=1)
    return simple_match

def compute_order_match(target, exemplar, concept):
    # fill nan rows with empty string
    exemplar = exemplar.fillna("")
    exact_match = exemplar.apply(lambda row: row == target[row.name], axis=1)
    substring_match = exemplar.apply(lambda row: row.apply(lambda x: target[row.name] in x), axis=1)
    
    exemplar_noconcept = exemplar.map(lambda x: x.replace(f"{concept} ", "").strip() if isinstance(x, str) else x)
    target_noconcept = target.map(lambda x: x.replace("{concept} ", "").strip() if isinstance(x, str) else x)
    substring_match_noconcept = exemplar_noconcept.apply(lambda row: row.apply(lambda x: target_noconcept[row.name] in x), axis=1)
    
    return exact_match, substring_match, substring_match_noconcept

    
def get_topn_exemplars(data, concept, sort, filter, n=5):
    is_human = True if "exemplar_string" in data.columns else False
    selected = data[data.concept == (concept.upper() if is_human else concept)].sort_values(by=sort, ascending=False)

    if filter:
        selected = selected[selected["abs_freq"]] > 0
        raise NotImplementedError()
    
    selected = selected["exemplar_string" if is_human else "concept_exemplar"].tolist()
    selected = selected[:n]

    if not is_human:
        selected = [exemplar.split("_")[-1] for exemplar in selected]
    
    if (not is_human and len(selected) < n):
        selected += [None for i in range(n - len(selected))]


    return selected


if __name__ == "__main__":
    from argparse import ArgumentParser
    parser = ArgumentParser()
    parser.add_argument("--temp", type=float, default=0.5)
    parser.add_argument("--filter", action="store_true")
    parser.add_argument("--sort", type=str, default="availability")
    args = parser.parse_args()
    main(args)